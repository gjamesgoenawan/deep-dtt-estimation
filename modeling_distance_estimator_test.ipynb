{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b862c40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aircraft-detection custom utils\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "auxiliary_head(\n",
       "  (fc_1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc_2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import tqdm.notebook as tqdm\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from utils.dataset import load_compiled_data, ObjectDetectorDataset\n",
    "from utils.head import input_reg, auxiliary_head, mlp_dual, LSTM_DE\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "reg_camera_1 = input_reg().to(device)\n",
    "reg_camera_2 = input_reg().to(device)\n",
    "aux_head = auxiliary_head().to(device)\n",
    "\n",
    "reg_camera_1.load_state_dict(torch.load('models/head/reg_camera_1.pt'))\n",
    "reg_camera_2.load_state_dict(torch.load('models/head/reg_camera_2.pt'))\n",
    "aux_head.load_state_dict(torch.load('models/head/aux_head.pt'))\n",
    "\n",
    "reg_camera_1.eval()\n",
    "reg_camera_2.eval()\n",
    "aux_head.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eebaa9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_compiled_data_custom(ts=[1], ws=[1], rs=[1], offset = [[0,0,0,0],[0,0,0,0]], divider = [[1,1,1,1],[1,1,1,1]], device = torch.device('cpu')):\n",
    "    camera_1_dets = []\n",
    "    camera_2_dets = []\n",
    "    camera_1_ys = []\n",
    "    camera_2_ys = []\n",
    "\n",
    "    offset = torch.tensor(offset, device =device)\n",
    "    divider = torch.tensor(divider, device =device)\n",
    "\n",
    "    for t in ts:\n",
    "        for w in ws:\n",
    "            for r in rs:\n",
    "                with open(f\"output/object_detector/t{t}w{w}r{r}.pkl\", 'rb') as f:\n",
    "                        box, scores, gt_distance = pkl.load(f)\n",
    "                gt_distance = torch.from_numpy(gt_distance)\n",
    "                camera_1_det = torch.cat(((box[:, :4].float()[:len(gt_distance)]), gt_distance[:, 0].unsqueeze(1) / 10, scores[:, 0].unsqueeze(1)), axis = 1)\n",
    "                camera_2_det = torch.cat(((box[:, 4:].float()[:len(gt_distance)]), gt_distance[:, 0].unsqueeze(1) / 10, scores[:, 1].unsqueeze(1)), axis = 1)\n",
    "                \n",
    "                # Remove Missing Detection\n",
    "                \n",
    "                f_camera_1_available_detection = torch.all(torch.logical_not(camera_1_det[:, :4] == 0), dim = 1)\n",
    "                f_camera_2_available_detection = torch.all(torch.logical_not(camera_2_det[:, :4] == 0), dim = 1)\n",
    "                f_camera_1_gt_more_than_1nm = camera_1_det[:, -2] > 0.1\n",
    "                f_camera_2_gt_more_than_1nm = camera_2_det[:, -2] > 0.1\n",
    "                f_camera_all_available_detection = torch.logical_and(f_camera_1_available_detection, f_camera_2_available_detection)\n",
    "                \n",
    "                \n",
    "                #f_camera_1 = torch.logical_and(f_camera_1_available_detection, f_camera_1_gt_more_than_1nm)\n",
    "                #f_camera_2 = torch.logical_and(f_camera_2_available_detection, f_camera_2_gt_more_than_1nm)\n",
    "                \n",
    "                \n",
    "                camera_1_det = camera_1_det[f_camera_all_available_detection].float()\n",
    "                camera_2_det = camera_2_det[f_camera_all_available_detection].float()\n",
    "    \n",
    "\n",
    "                camera_1_dets.append(camera_1_det[:, :4])\n",
    "                camera_1_ys.append(camera_1_det[:, -2:])\n",
    "                camera_2_dets.append(camera_2_det[:, :4])\n",
    "                camera_2_ys.append(camera_2_det[:, -2:])\n",
    "                \n",
    "    camera_1_y = torch.cat(camera_1_ys).to(device)\n",
    "    camera_2_y = torch.cat(camera_2_ys).to(device)      \n",
    "    camera_1_dets = torch.cat(camera_1_dets)\n",
    "    camera_2_dets = torch.cat(camera_2_dets)\n",
    "    \n",
    "    # Convert to (X_centroid, Y_centroid, X_width, Y_width)\n",
    "    camera_1_x = torch.zeros(camera_1_dets[:, :4].shape, device = device)\n",
    "    camera_2_x = torch.zeros(camera_2_dets[:, :4].shape, device = device)\n",
    "    camera_1_x[:, 0] = (camera_1_dets[:, 0] + camera_1_dets[:, 2]) / 2\n",
    "    camera_1_x[:, 1] = (camera_1_dets[:, 1] + camera_1_dets[:, 3]) / 2\n",
    "    camera_1_x[:, 2] = (camera_1_dets[:, 2] - camera_1_dets[:, 0])\n",
    "    camera_1_x[:, 3] = (camera_1_dets[:, 3] - camera_1_dets[:, 1])\n",
    "    camera_2_x[:, 0] = (camera_2_dets[:, 0] + camera_2_dets[:, 2]) / 2\n",
    "    camera_2_x[:, 1] = (camera_2_dets[:, 1] + camera_2_dets[:, 3]) / 2\n",
    "    camera_2_x[:, 2] = (camera_2_dets[:, 2] - camera_2_dets[:, 0])\n",
    "    camera_2_x[:, 3] = (camera_2_dets[:, 3] - camera_2_dets[:, 1])\n",
    "    \n",
    "    camera_1_x = (camera_1_x - offset[0]) / divider[0]\n",
    "    camera_2_x = (camera_2_x - offset[1]) / divider[1]\n",
    "    \n",
    "    print(f\"\"\"Data Statistic:\n",
    "          Camera 1:\n",
    "          Mean: {torch.mean(camera_1_x, 0).tolist()}\n",
    "          Std : {torch.std(camera_1_x, 0).tolist()}\n",
    "          \n",
    "          Camera 2:\n",
    "          Mean: {torch.mean(camera_2_x, 0).tolist()}\n",
    "          Std : {torch.std(camera_2_x, 0).tolist()}\n",
    "          \"\"\")\n",
    "    return camera_1_x, camera_1_y, camera_2_x, camera_2_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abba1443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Statistic:\n",
      "          Camera 1:\n",
      "          Mean: [0.23115402460098267, 0.13664153218269348, 0.3269054591655731, 0.23455950617790222]\n",
      "          Std : [0.21913321316242218, 0.10741851478815079, 0.20001117885112762, 0.20704865455627441]\n",
      "          \n",
      "          Camera 2:\n",
      "          Mean: [0.28849586844444275, 0.3268456757068634, 0.3711751103401184, 0.2691517174243927]\n",
      "          Std : [0.26450350880622864, 0.19246098399162292, 0.23262810707092285, 0.2345651388168335]\n",
      "          \n",
      "Data Statistic:\n",
      "          Camera 1:\n",
      "          Mean: [0.24771815538406372, 0.10636551678180695, 0.3369009792804718, 0.24522686004638672]\n",
      "          Std : [0.23109997808933258, 0.09466056525707245, 0.20359617471694946, 0.21714016795158386]\n",
      "          \n",
      "          Camera 2:\n",
      "          Mean: [0.30855682492256165, 0.2939678430557251, 0.3898959457874298, 0.29688432812690735]\n",
      "          Std : [0.2778509855270386, 0.2029714286327362, 0.24246175587177277, 0.25780919194221497]\n",
      "          \n",
      "Data Statistic:\n",
      "          Camera 1:\n",
      "          Mean: [0.2541612684726715, 0.15522243082523346, 0.33605489134788513, 0.24713632464408875]\n",
      "          Std : [0.2537042200565338, 0.1441500037908554, 0.21661770343780518, 0.22672869265079498]\n",
      "          \n",
      "          Camera 2:\n",
      "          Mean: [0.2812615633010864, 0.327648401260376, 0.36480095982551575, 0.2620355486869812]\n",
      "          Std : [0.25796034932136536, 0.18658660352230072, 0.22886796295642853, 0.22864417731761932]\n",
      "          \n",
      "Data Statistic:\n",
      "          Camera 1:\n",
      "          Mean: [0.2738477289676666, 0.13646306097507477, 0.3456593155860901, 0.2576455771923065]\n",
      "          Std : [0.2615092098712921, 0.17236676812171936, 0.21653327345848083, 0.23543140292167664]\n",
      "          \n",
      "          Camera 2:\n",
      "          Mean: [0.28270238637924194, 0.29571533203125, 0.3662557899951935, 0.2728385627269745]\n",
      "          Std : [0.2569683790206909, 0.18491311371326447, 0.22845248878002167, 0.23856738209724426]\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "# Data Loading & Removing Outlier\n",
    "norm_offset = [[20.7227, 271.4375,   9.0000,   5.5000], [5.3496, 248.5000,  10.1094,   4.5000]]\n",
    "norm_divider = [[1894.2773,  798.0625,  174.2500,   67.5000], [1908.6504,  396.5000,   99.8906,   42.5000]]\n",
    "train_camera_1_x, train_camera_1_y, train_camera_2_x, train_camera_2_y = load_compiled_data_custom(ts=[1,2,5],ws=[1],rs=[1,2], offset = norm_offset, divider = norm_divider, device = device)\n",
    "test_camera_1_x, test_camera_1_y, test_camera_2_x, test_camera_2_y = load_compiled_data_custom(ts=[1,2,5],ws=[1],rs=[3], offset = norm_offset, divider = norm_divider, device = device)\n",
    "ff_train = torch.logical_and((train_camera_1_x[:, 1] < 0.75), (train_camera_2_x[:, 1] < 1.5))\n",
    "ff_test = torch.logical_and((test_camera_1_x[:, 1] < 0.75), (test_camera_2_x[:, 1] < 1.5))\n",
    "train_camera_1_x = train_camera_1_x[ff_train]\n",
    "train_camera_1_y = train_camera_1_y[ff_train]\n",
    "train_camera_2_x = train_camera_2_x[ff_train]\n",
    "train_camera_2_y = train_camera_2_y[ff_train]\n",
    "test_camera_1_x = test_camera_1_x[ff_test]\n",
    "test_camera_1_y = test_camera_1_y[ff_test]\n",
    "test_camera_2_x = test_camera_2_x[ff_test]\n",
    "test_camera_2_y = test_camera_2_y[ff_test]\n",
    "train_2cam_x = torch.stack((reg_camera_1(train_camera_1_x), reg_camera_2(train_camera_2_x)), axis = 1).detach()\n",
    "test_2cam_x = torch.stack((reg_camera_1(test_camera_1_x), reg_camera_2(test_camera_2_x)), axis = 1).detach()\n",
    "train_2cam_y = train_camera_1_y\n",
    "test_2cam_y = test_camera_1_y\n",
    "\n",
    "train_camera_1_x, train_camera_1_y, train_camera_2_x, train_camera_2_y = load_compiled_data(ts=[1,2,5],ws=[1],rs=[1,2], offset = norm_offset, divider = norm_divider, device = device)\n",
    "test_camera_1_x, test_camera_1_y, test_camera_2_x, test_camera_2_y = load_compiled_data(ts=[1,2,5],ws=[1],rs=[3], offset = norm_offset, divider = norm_divider, device = device)\n",
    "ff_train_1 = train_camera_1_x[:, 1] < 0.75\n",
    "ff_train_2 = train_camera_2_x[:, 1] < 1.5\n",
    "ff_test_1 = test_camera_1_x[:, 1] < 0.75\n",
    "ff_test_2 = test_camera_2_x[:, 1] < 1.5\n",
    "train_camera_1_x = train_camera_1_x[ff_train_1]\n",
    "train_camera_1_y = train_camera_1_y[ff_train_1]\n",
    "train_camera_2_x = train_camera_2_x[ff_train_2]\n",
    "train_camera_2_y = train_camera_2_y[ff_train_2]\n",
    "test_camera_1_x = test_camera_1_x[ff_test_1]\n",
    "test_camera_1_y = test_camera_1_y[ff_test_1]\n",
    "test_camera_2_x = test_camera_2_x[ff_test_2]\n",
    "test_camera_2_y = test_camera_2_y[ff_test_2]\n",
    "train_1cam_x = torch.cat((reg_camera_1(train_camera_1_x), reg_camera_2(train_camera_2_x))).unsqueeze(1).detach()\n",
    "test_1cam_x = torch.cat((reg_camera_1(test_camera_1_x), reg_camera_2(test_camera_2_x))).unsqueeze(1).detach()\n",
    "train_1cam_y = torch.cat((train_camera_1_y, train_camera_2_y))\n",
    "test_1cam_y = torch.cat((test_camera_1_y, test_camera_2_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3287fa4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_DE(\n",
       "  (LSTM): LSTM(256, 256, num_layers=2, batch_first=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_de = LSTM_DE().cuda()\n",
    "sequential_de.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c9d9cec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(sequential_de.parameters(), lr=learning_rate, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d2674d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df794464efc74a05ac0c13ede9a88234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 996/700000 [00:21<4:11:38, 46.30it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "Epoch 1000\n",
      "Train Loss   : 0.007975622080266476\n",
      "Test Loss    : 0.004990849178284407\n",
      "Test MAPE    : 0.24%\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [88]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(sequential_de(train_1cam_x)\u001b[38;5;241m.\u001b[39msqueeze(), train_1cam_y[:, \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     10\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 11\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     14\u001b[0m     sequential_de\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/miniconda3/envs/ad/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/ad/lib/python3.10/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/miniconda3/envs/ad/lib/python3.10/site-packages/torch/optim/sgd.py:151\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m             momentum_buffer_list\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmomentum_buffer\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 151\u001b[0m \u001b[43msgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_p_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmomentum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdampening\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnesterov\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# update momentum_buffers in state\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p, momentum_buffer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(params_with_grad, momentum_buffer_list):\n",
      "File \u001b[0;32m~/miniconda3/envs/ad/lib/python3.10/site-packages/torch/optim/sgd.py:202\u001b[0m, in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_sgd\n\u001b[0;32m--> 202\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m     \u001b[49m\u001b[43md_p_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdampening\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m     \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnesterov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ad/lib/python3.10/site-packages/torch/optim/sgd.py:238\u001b[0m, in \u001b[0;36m_single_tensor_sgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    236\u001b[0m     momentum_buffer_list[i] \u001b[38;5;241m=\u001b[39m buf\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     \u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdampening\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nesterov:\n\u001b[1;32m    241\u001b[0m     d_p \u001b[38;5;241m=\u001b[39m d_p\u001b[38;5;241m.\u001b[39madd(buf, alpha\u001b[38;5;241m=\u001b[39mmomentum)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Shallow 1 Camera Training\n",
    "sequential_de.train()\n",
    "losses = []\n",
    "tlosses = []\n",
    "epochs = tqdm.tqdm(iterable=range(700000), leave=True)\n",
    "for epoch in epochs:\n",
    "    optimizer.zero_grad()\n",
    "    # camera_1\n",
    "    loss = criterion(sequential_de(train_1cam_x).squeeze(), train_1cam_y[:, 0]) * 1000\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        sequential_de.eval()\n",
    "        ypred = sequential_de(test_1cam_x).squeeze()\n",
    "        tloss = criterion(ypred, test_1cam_y[:, 0]) * 1000\n",
    "        \n",
    "        display.clear_output(wait=True)\n",
    "        display.display(epochs.container)\n",
    "        print(\"==========================\\nEpoch {}\".format(epoch))\n",
    "        print(f'Train Loss   : {loss.item()}')\n",
    "        print(f'Test Loss    : {tloss.item()}')\n",
    "        print(f'Test MAPE    : {((abs(ypred-test_1cam_y[:, 0])/ypred).mean() * 100).item():.2f}%')\n",
    "        print(\"==========================\\n\")\n",
    "        losses.append([loss.item()])\n",
    "        tlosses.append([tloss.item()])\n",
    "        sequential_de.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1ff6c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sequential_de.state_dict(), 'models/head/sequential_de.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "499fb1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_de.load_state_dict(torch.load('models/head/sequential_de.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf76866",
   "metadata": {},
   "source": [
    "# Dropout Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "257eb4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_de = LSTM_DE().cuda()\n",
    "sequential_de.train()\n",
    "tlosses_deep = []\n",
    "tlosses_shallow = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d220369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(sequential_de.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68f3b3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26676, 2, 256]) torch.Size([26676, 2])\n"
     ]
    }
   ],
   "source": [
    "od_dataset = ObjectDetectorDataset(train_2cam_x, train_2cam_y)\n",
    "od_dataloader = DataLoader(od_dataset, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d060fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8d038e232e46e0838912b599d2fec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 2/8000 [00:04<3:13:53,  1.45s/it]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "Epoch 2\n",
      "Train Loss           : 8.695456926943734e-05\n",
      "\n",
      "Test Shallow Loss    : 6.014377868268639e-05\n",
      "Test Deep Loss       : 3.481760359136388e-05\n",
      "\n",
      "Test Shallow MAPE    : 0.29%\n",
      "Test Deep MAPE       : 0.22%\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     ypred \u001b[38;5;241m=\u001b[39m sequential_de(train_minibatch_x)[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(ypred, train_minibatch_y[:, \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ad/lib/python3.10/site-packages/torch/_tensor.py:428\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_tensor_str\u001b[38;5;241m.\u001b[39m_str(\u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents)\n\u001b[0;32m--> 428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    430\u001b[0m ):\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03m    The graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;124;03m            used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Deep 2 Camera Training\n",
    "sequential_de.train()\n",
    "epochs = tqdm.tqdm(iterable=range(8000), leave=True)\n",
    "for epoch in epochs:\n",
    "    for train_minibatch_x, train_minibatch_y in od_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        drop_choice = random.randint(0,3)\n",
    "        \n",
    "        if drop_choice == 0:\n",
    "            train_minibatch_x = train_minibatch_x[:, 0:1, :]\n",
    "        elif drop_choice == 1:\n",
    "            train_minibatch_x = train_minibatch_x[:, 1:, :]\n",
    "        else:\n",
    "            pass\n",
    "        ypred = sequential_de(train_minibatch_x)[:, -1].squeeze()\n",
    "        loss = criterion(ypred, train_minibatch_y[:, 0]) * 10\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 1 == 0:\n",
    "        sequential_de.eval()\n",
    "        ypred_shallow = sequential_de(test_1cam_x).squeeze()\n",
    "        tloss_shallow = criterion(ypred_shallow, test_1cam_y[:, 0]) * 10\n",
    "        ypred_deep = sequential_de(test_2cam_x).squeeze()[:, 1]\n",
    "        tloss_deep = criterion(ypred_deep, test_2cam_y[:, 0]) * 10\n",
    "        \n",
    "        test_deep_mape = ((abs(ypred_deep-test_2cam_y[:, 0])/ypred_deep).mean() * 100).item()\n",
    "        test_shallow_mape = ((abs(ypred_shallow-test_1cam_y[:, 0])/ypred_shallow).mean() * 100).item()\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(epochs.container)\n",
    "        print(\"==========================\\nEpoch {}\".format(epoch))\n",
    "        print(f'Train Loss           : {loss.item()}\\n')\n",
    "        \n",
    "        print(f'Test Shallow Loss    : {tloss_shallow.item()}')\n",
    "        print(f'Test Deep Loss       : {tloss_deep.item()}\\n')\n",
    "        \n",
    "        print(f'Test Shallow MAPE    : {test_shallow_mape:.2f}%')\n",
    "        print(f'Test Deep MAPE       : {test_deep_mape:.2f}%')\n",
    "        \n",
    "        print(\"==========================\\n\")\n",
    "        \n",
    "        tlosses_deep.append(test_deep_mape)\n",
    "        tlosses_shallow.append(test_shallow_mape)\n",
    "        sequential_de.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0deabb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sequential_de.state_dict(), 'models/head/sequential_de_random_training.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14aff5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_de.load_state_dict(torch.load('models/head/sequential_de_random_training.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ea2079",
   "metadata": {},
   "source": [
    "# Old OD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46810ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Statistic:\n",
      "          Camera 1:\n",
      "          Mean: [0.23115402460098267, 0.13664153218269348, 0.3269054591655731, 0.23455950617790222]\n",
      "          Std : [0.21913321316242218, 0.10741851478815079, 0.20001117885112762, 0.20704865455627441]\n",
      "          \n",
      "          Camera 2:\n",
      "          Mean: [0.28849586844444275, 0.3268456757068634, 0.3711751103401184, 0.2691517174243927]\n",
      "          Std : [0.26450350880622864, 0.19246098399162292, 0.23262810707092285, 0.2345651388168335]\n",
      "          \n",
      "Data Statistic:\n",
      "          Camera 1:\n",
      "          Mean: [0.24771815538406372, 0.10636551678180695, 0.3369009792804718, 0.24522686004638672]\n",
      "          Std : [0.23109997808933258, 0.09466056525707245, 0.20359617471694946, 0.21714016795158386]\n",
      "          \n",
      "          Camera 2:\n",
      "          Mean: [0.30855682492256165, 0.2939678430557251, 0.3898959457874298, 0.29688432812690735]\n",
      "          Std : [0.2778509855270386, 0.2029714286327362, 0.24246175587177277, 0.25780919194221497]\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "norm_offset = [[20.7227, 271.4375,   9.0000,   5.5000], [5.3496, 248.5000,  10.1094,   4.5000]]\n",
    "norm_divider = [[1894.2773,  798.0625,  174.2500,   67.5000], [1908.6504,  396.5000,   99.8906,   42.5000]]\n",
    "train_camera_1_x, train_camera_1_y, train_camera_2_x, train_camera_2_y = load_compiled_data_custom(ts=[1,2,5],ws=[1],rs=[1,2], offset = norm_offset, divider = norm_divider, device = device)\n",
    "test_camera_1_x, test_camera_1_y, test_camera_2_x, test_camera_2_y = load_compiled_data_custom(ts=[1,2,5],ws=[1],rs=[3], offset = norm_offset, divider = norm_divider, device = device)\n",
    "ff_train = torch.logical_and((train_camera_1_x[:, 1] < 0.75), (train_camera_2_x[:, 1] < 1.5))\n",
    "ff_test = torch.logical_and((test_camera_1_x[:, 1] < 0.75), (test_camera_2_x[:, 1] < 1.5))\n",
    "train_camera_1_x = train_camera_1_x[ff_train]\n",
    "train_camera_1_y = train_camera_1_y[ff_train]\n",
    "train_camera_2_x = train_camera_2_x[ff_train]\n",
    "train_camera_2_y = train_camera_2_y[ff_train]\n",
    "test_camera_1_x = test_camera_1_x[ff_test]\n",
    "test_camera_1_y = test_camera_1_y[ff_test]\n",
    "test_camera_2_x = test_camera_2_x[ff_test]\n",
    "test_camera_2_y = test_camera_2_y[ff_test]\n",
    "train_2cam_x = torch.cat((train_camera_1_x, train_camera_2_x), axis = 1).detach()\n",
    "test_2cam_x = torch.cat((test_camera_1_x, test_camera_2_x), axis = 1).detach()\n",
    "train_2cam_y = train_camera_1_y\n",
    "test_2cam_y = test_camera_1_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "295a69c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp_dual().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3de540b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96afe0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "Epoch 1000\n",
      "Train Deep Loss      : 0.0008542968425899744\n",
      "\n",
      "Test Deep Loss       : 0.0006653121090494096\n",
      "\n",
      "Test Deep MAPE       : 0.28%\n",
      "==========================\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m ypred \u001b[38;5;241m=\u001b[39m model(train_2cam_x)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(ypred, train_2cam_y[:, \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ad/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ad/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# old od training\n",
    "sequential_de.train()\n",
    "losses = []\n",
    "tlosses = []\n",
    "epochs = tqdm.tqdm(iterable=range(700000), leave=True)\n",
    "for epoch in epochs:\n",
    "    optimizer.zero_grad()\n",
    "    # camera_1\n",
    "    ypred = model(train_2cam_x).squeeze()\n",
    "    loss = criterion(ypred, train_2cam_y[:, 0]) * 100\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        sequential_de.eval()\n",
    "        ypred = model(test_2cam_x).squeeze()\n",
    "        tloss = criterion(ypred, test_2cam_y[:, 0]) * 100\n",
    "        \n",
    "        display.clear_output(wait=True)\n",
    "        #display.display(epochs.container)\n",
    "        print(\"==========================\\nEpoch {}\".format(epoch))\n",
    "        print(f'Train Deep Loss      : {loss.item()}\\n')\n",
    "        print(f'Test Deep Loss       : {tloss.item()}\\n')\n",
    "        print(f'Test Deep MAPE       : {((abs(ypred-test_2cam_y[:, 0])/ypred).mean() * 100).item():.2f}%')\n",
    "        \n",
    "        print(\"==========================\\n\")\n",
    "        #losses.append([loss.item()])\n",
    "        #tlosses.append([tloss.item()])\n",
    "        sequential_de.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c871eee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad",
   "language": "python",
   "name": "ad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
